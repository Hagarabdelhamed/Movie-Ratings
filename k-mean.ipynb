{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"imdb_top_2000_movies.csv\")\n",
    "data.drop(columns=[\"Release Year\", \"Metascore\", \"Votes\", \"Genre\", \"Gross\", \"Cast\", \"Director\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removing Outliers Before Start K-Mean Because It's Sensentive To Outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Outliers_IQR(data):\n",
    "    Q1 = np.percentile(data[ \"Duration\"], 25)\n",
    "    Q3 = np.percentile(data[ \"Duration\"], 75)\n",
    "    IQR = Q3 - Q1\n",
    "    LowerBound = Q1 - 1.5 * IQR\n",
    "    UpperBound = Q3 + 1.5 * IQR\n",
    "    OutliersIQR = (data[ \"Duration\"] < LowerBound) | (data[ \"Duration\"] > UpperBound)\n",
    "    Outliers = data[OutliersIQR]\n",
    "    print(F\"({len(Outliers)} movies)\")\n",
    "    Data_Without_Outliers = data[~OutliersIQR]\n",
    "    return Data_Without_Outliers,Outliers\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point, centroid):\n",
    "    return np.sqrt(np.sum((point - centroid) ** 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get The Initial CENTROIDS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Initialize_Centroids(data, num_clusters):\n",
    "    imdb_ratings = data[ \"Duration\"]\n",
    "    movie_names = data['Movie Name']\n",
    "    \n",
    "    centroids_idx = np.random.choice(len(imdb_ratings), size=num_clusters, replace=False)\n",
    "    centroids = imdb_ratings.iloc[centroids_idx].values\n",
    "    centroid_movie_names = movie_names.iloc[centroids_idx].values\n",
    "    \n",
    "    return centroids, centroid_movie_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Get The Nearest Movie To The Centroid*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_to_clusters(data, centroids):\n",
    "    movie_names = []\n",
    "    imdb_ratings = []\n",
    "    cluster_assignments = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        movie = row['Movie Name']\n",
    "        rating = row['Duration']\n",
    "\n",
    "        movie_names.append(movie)\n",
    "        imdb_ratings.append(rating)\n",
    "\n",
    "        distances = [euclidean_distance(rating, centroid) for centroid in centroids]\n",
    "\n",
    "        nearest_centroid_index = np.argmin(distances)\n",
    "\n",
    "        cluster_assignments.append(nearest_centroid_index)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Movie Name': movie_names,\n",
    "        'Duration': imdb_ratings,\n",
    "        'Cluster': cluster_assignments\n",
    "    })\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-MEAN ALGORITHM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(data, num_clusters, max_iterations=100):\n",
    "    centroids, _ = Initialize_Centroids(data, num_clusters)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        assigned_clusters = assign_to_clusters(data, centroids)\n",
    "        \n",
    "        new_centroids = []\n",
    "        cluster_movie_names = [[] for _ in range(num_clusters)] \n",
    "        \n",
    "        for i in range(num_clusters):\n",
    "            cluster_data = assigned_clusters[assigned_clusters['Cluster'] == i]\n",
    "            if len(cluster_data) > 0:\n",
    "                new_centroid = cluster_data[ \"Duration\"].mean()\n",
    "                cluster_movie_names[i] = cluster_data['Movie Name'].tolist()  \n",
    "            else:\n",
    "                new_centroid = centroids[i]\n",
    "            new_centroids.append(new_centroid)\n",
    "        \n",
    "        new_centroids = np.array(new_centroids)\n",
    "        \n",
    "        if np.array_equal(centroids, new_centroids):\n",
    "            break\n",
    "        \n",
    "        print(f\"Iteration {iteration + 1}:\")\n",
    "        print(\"Old Centroids:\", centroids)\n",
    "        print(\"New Centroids:\", new_centroids)\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    assigned_clusters['Movie Names'] = [cluster_movie_names[c] for c in assigned_clusters['Cluster']]\n",
    "    \n",
    "    return centroids, assigned_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72 movies)\n",
      "Iteration 1:\n",
      "Old Centroids: [ 90  88 112]\n",
      "New Centroids: [ 95.42043222  83.5862069  120.77708006]\n",
      "Iteration 2:\n",
      "Old Centroids: [ 95.42043222  83.5862069  120.77708006]\n",
      "New Centroids: [ 99.2242268   84.35502959 125.43743642]\n",
      "Iteration 3:\n",
      "Old Centroids: [ 99.2242268   84.35502959 125.43743642]\n",
      "New Centroids: [101.86492891  86.20987654 127.98573127]\n",
      "Iteration 4:\n",
      "Old Centroids: [101.86492891  86.20987654 127.98573127]\n",
      "New Centroids: [104.25647349  88.39215686 129.54078947]\n",
      "Iteration 5:\n",
      "Old Centroids: [104.25647349  88.39215686 129.54078947]\n",
      "New Centroids: [106.1625      89.75227273 131.01453488]\n",
      "Iteration 6:\n",
      "Old Centroids: [106.1625      89.75227273 131.01453488]\n",
      "New Centroids: [107.62181818  90.42474227 132.54854369]\n",
      "Iteration 7:\n",
      "Old Centroids: [107.62181818  90.42474227 132.54854369]\n",
      "New Centroids: [109.39778325  91.51871658 134.02882883]\n",
      "Iteration 8:\n",
      "Old Centroids: [109.39778325  91.51871658 134.02882883]\n",
      "New Centroids: [110.43125     92.16144975 134.87907869]\n",
      "Iteration 9:\n",
      "Old Centroids: [110.43125     92.16144975 134.87907869]\n",
      "New Centroids: [111.4         92.79663609 135.58299595]\n",
      "Iteration 10:\n",
      "Old Centroids: [111.4         92.79663609 135.58299595]\n",
      "New Centroids: [112.22905759  93.31457431 136.19745223]\n",
      "Iteration 11:\n",
      "Old Centroids: [112.22905759  93.31457431 136.19745223]\n",
      "New Centroids: [112.73057644  93.31457431 137.14645309]\n",
      "Iteration 12:\n",
      "Old Centroids: [112.73057644  93.31457431 137.14645309]\n",
      "New Centroids: [113.23056653  93.83060109 137.14645309]\n",
      "Iteration 13:\n",
      "Old Centroids: [113.23056653  93.83060109 137.14645309]\n",
      "New Centroids: [113.64930114  93.83060109 137.97799511]\n",
      "[ 92 144 112] ['Saved!' 'Chitty Chitty Bang Bang' 'Fahrenheit 451']\n",
      "Final Centroids:\n",
      "[113.64930114  93.83060109 137.97799511]\n",
      "\n",
      "Final Clusters:\n",
      "                              Movie Name  Duration  Cluster  \\\n",
      "0                        Ordinary People       124        0   \n",
      "1                             Straw Dogs       113        0   \n",
      "2     Close Encounters of the Third Kind       138        2   \n",
      "3                        The Dirty Dozen       150        2   \n",
      "4                        Rosemary's Baby       137        2   \n",
      "...                                  ...       ...      ...   \n",
      "1923                  The Young Victoria       105        0   \n",
      "1924                         Tooth Fairy       101        1   \n",
      "1925                      The Informant!       108        0   \n",
      "1926                     Youth in Revolt        90        1   \n",
      "1927                          Quarantine        89        1   \n",
      "\n",
      "                                            Movie Names  \n",
      "0     [Ordinary People, Straw Dogs, Cabaret, Psycho,...  \n",
      "1     [Ordinary People, Straw Dogs, Cabaret, Psycho,...  \n",
      "2     [Close Encounters of the Third Kind, The Dirty...  \n",
      "3     [Close Encounters of the Third Kind, The Dirty...  \n",
      "4     [Close Encounters of the Third Kind, The Dirty...  \n",
      "...                                                 ...  \n",
      "1923  [Ordinary People, Straw Dogs, Cabaret, Psycho,...  \n",
      "1924  [Notorious, Rope, Friday the 13th, Carrie, 12 ...  \n",
      "1925  [Ordinary People, Straw Dogs, Cabaret, Psycho,...  \n",
      "1926  [Notorious, Rope, Friday the 13th, Carrie, 12 ...  \n",
      "1927  [Notorious, Rope, Friday the 13th, Carrie, 12 ...  \n",
      "\n",
      "[1928 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data_without_outliers, _ = Outliers_IQR(data)\n",
    "num_clusters = 3  # Set the number of clusters\n",
    "final_centroids, final_clusters = k_means(data_without_outliers, num_clusters)\n",
    "InitializeCentroids, _ =Initialize_Centroids(data_without_outliers, num_clusters)\n",
    "print(InitializeCentroids,_)\n",
    "print(\"Final Centroids:\")\n",
    "print(final_centroids)\n",
    "print(\"\\nFinal Clusters:\")\n",
    "print(final_clusters)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_data(filepath, percentage):\n",
    "    try:\n",
    "        data = pd.read_csv(filepath)\n",
    "        num_records = int(len(data) * (percentage / 100))\n",
    "        data = data.head(num_records)\n",
    "\n",
    "        # Data Preprocessing\n",
    "        data.drop(columns=[\"Release Year\", \"Metascore\", \"Votes\", \"Genre\", \"Gross\", \"Cast\", \"Director\"], inplace=True)\n",
    "\n",
    "        # Removing Outliers\n",
    "        data, outliers = Outliers_IQR(data)\n",
    "\n",
    "        return data, outliers\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))\n",
    "        return None, None\n",
    "\n",
    "def load_data():\n",
    "    filepath = filedialog.askopenfilename(title=\"Select File\")\n",
    "    if filepath:\n",
    "        data_entry.delete(0, tk.END)\n",
    "        data_entry.insert(0, filepath)\n",
    "\n",
    "def run_clustering():\n",
    "    filepath = data_entry.get()\n",
    "    percentage = percentage_entry.get()\n",
    "    num_clusters = int(clusters_entry.get())\n",
    "\n",
    "    try:\n",
    "        percentage = float(percentage)\n",
    "        if percentage <= 0 or percentage > 100:\n",
    "            raise ValueError(\"Percentage must be between 0 and 100\")\n",
    "    except ValueError:\n",
    "        messagebox.showerror(\"Error\", \"Invalid percentage value\")\n",
    "        return\n",
    "\n",
    "    data, outliers = load_and_process_data(filepath, percentage)\n",
    "\n",
    "    if data is None:\n",
    "        return\n",
    "\n",
    "    # Use the preprocessed data without outliers\n",
    "    data_without_outliers, _ = Outliers_IQR(data)\n",
    "    # print(\"Data without outliers:\")\n",
    "    # print(data_without_outliers)\n",
    "\n",
    "    initial_centroids, _ = Initialize_Centroids(data_without_outliers, num_clusters)\n",
    "\n",
    "    result_text.delete(\"1.0\", tk.END)\n",
    "    result_text.insert(tk.END, \"Initial centroids:\\n\")\n",
    "    for centroid in initial_centroids:\n",
    "        result_text.insert(tk.END, f\"- Centroid: {centroid}\\n\")\n",
    "    result_text.insert(tk.END, \"\\n\")\n",
    "\n",
    "    final_centroids, clusters = k_means(data_without_outliers, num_clusters)\n",
    "\n",
    "    result_text.insert(tk.END, \"Final centroids:\\n\")\n",
    "    for i, centroid in enumerate(final_centroids):\n",
    "        result_text.insert(tk.END, f\"- Centroid {i+1}: {centroid}\\n\")\n",
    "    result_text.insert(tk.END, \"\\n\\n\")\n",
    "\n",
    "    for i, (_, cluster) in enumerate(clusters.groupby('Cluster')):\n",
    "            movie_list = \"\\n - \".join(cluster['Movie Names'].iloc[0])\n",
    "            result_text.insert(tk.END, f\"\\n\\nCluster {i+1} Movies ({len(cluster)} movies) : \\n - {movie_list}\\n\")\n",
    "\n",
    "    result_text.insert(tk.END, \"\\nOutliers:\\n\")\n",
    "    for index, row in outliers.iterrows():\n",
    "            result_text.insert(tk.END, f\"- {row['Movie Name']}: {row[ \"Duration\"]}\\n\")\n",
    "   \n",
    "    # total_movies_in_clusters = sum(len(cluster) for _, cluster in clusters.groupby('Cluster'))\n",
    "\n",
    "    # for i, (_, cluster) in enumerate(clusters.groupby('Cluster')):\n",
    "    #     movie_list = \"\\n - \".join(cluster['Movie Names'].iloc[0])\n",
    "    #     result_text.insert(tk.END, f\"Cluster {i+1} Movies ({len(cluster)} movies) : \\n - {movie_list}\\n\")\n",
    "\n",
    "    # result_text.insert(tk.END, f\"\\nTotal movies in all clusters: {total_movies_in_clusters}\")\n",
    "\n",
    "\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"K-Means Clustering\")\n",
    "\n",
    "# File Selection\n",
    "file_frame = tk.Frame(root)\n",
    "file_frame.pack(pady=10)\n",
    "\n",
    "tk.Label(file_frame, text=\"Select File:\").pack(side=tk.LEFT)\n",
    "data_entry = tk.Entry(file_frame, width=50)\n",
    "data_entry.pack(side=tk.LEFT, padx=10)\n",
    "tk.Button(file_frame, text=\"Browse\", command=load_data).pack(side=tk.LEFT)\n",
    "\n",
    "# Percentage of Data\n",
    "percentage_frame = tk.Frame(root)\n",
    "percentage_frame.pack(pady=10)\n",
    "\n",
    "tk.Label(percentage_frame, text=\"Percentage of Data to Read:\").pack(side=tk.LEFT)\n",
    "percentage_entry = tk.Entry(percentage_frame, width=10)\n",
    "percentage_entry.pack(side=tk.LEFT, padx=10)\n",
    "tk.Label(percentage_frame, text=\"%\").pack(side=tk.LEFT)\n",
    "\n",
    "# Number of Clusters\n",
    "clusters_frame = tk.Frame(root)\n",
    "clusters_frame.pack(pady=10)\n",
    "\n",
    "tk.Label(clusters_frame, text=\"Number of Clusters (K):\").pack(side=tk.LEFT)\n",
    "clusters_entry = tk.Entry(clusters_frame, width=10)\n",
    "clusters_entry.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "# Run Button\n",
    "run_button = tk.Button(root, text=\"Run Clustering\", command=run_clustering)\n",
    "run_button.pack(pady=10)\n",
    "\n",
    "# Results Display\n",
    "result_text = tk.Text(root, height=20, width=80)\n",
    "result_text.pack()\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
